## [程序员的数学基础课](https://time.geekbang.org/column/intro/143) 黄申

#course #math

### why

- 机器学习表面上是“写程序”，但实际上剥去外表，本质上就是在研究数学
- 数学学得好不好，将会直接决定一个程序员有没有发展潜力。
  - 往大了说，数学它其实是一种思维模式，考验的是一个人归纳、总结和抽象的能力.
  - 往小了说，不管是数据结构与算法还是程序设计，其实底层很多原理或者思路都是源自于数学
- 编程语言是血肉，数学的思想和知识是灵魂
- 余数
  - 分页 根据记录总条数和每页展示条数，计算整体页数
  - 再难一点，奇偶校验、循环冗余检验、散列函数、密码学等等都有余数相关的知识。
  - 遇到这些问题的时候，能说不懂余数吗？只是很多时候没有想到可以用余数思想来解决相关问题罢了。那为什么没有想到呢？本质原因还是没有数学思维，还是数学的基础不够好。
- 定义好了专栏边界:只做程序员需要学的数学知识
- 数学理论和编程实践的结合其实是“决裂”的，所以学习数学的时候，不能太功利，觉得今天学完明天就能用得着的学习思路可以用在其他课程上，但放在数学里绝对不合适。
  - 数学知识总是比较抽象，特别是概率统计和线性代数中的概率、数据分布、矩阵、向量等概念。它们真的很不好理解，需要花时间琢磨，但是对于高级一点的程序设计而言，特别是和数据相关的算法，这些概念就非常重要了，这可都是先人总结出来的经验。
  - 如果能够将这些基本概念和核心理论都搞懂、搞透，那么面对系统框架设计、性能优化、准确率提升这些难题的时候，就能从更高的角度出发去解决问题，而不只是站在一个“熟练工”的视角，去增删改查。
- 希望数学能够成为一种基础能力，希望这个专栏能帮用数学思维来分析问题和解决问题。数学思想是启发思维的中枢，如果对数学有更好的理解，遇到问题的时候就能追本溯源，快、准、稳地找到解决方案。
- 对于程序开发这个职业来说，数学和英语是非常重要

### How

- 刘超 “学数学就像学一门新技术”
  - 不建议 将大学的数学书拿出来啃一遍，一来耗费大量时间，二来和实际应用结合不起来，往往该看的忽略了，不该看的费了半天劲用不上，过一阵又忘了
  - 学数学和学一门新技术一样：先用起来，了解实现原理，然后了解为什么这样实现
- 徐文浩  “先广度，再深度”
  - 投入时间学习数学原因，一来，在工作中用得上；二来，学点数学很多时候是个有趣的事。
    - 重新认识和理解“程序”和“问题的解决方案”这两件事情。
      - 大部分应用领域的核心解决方案，都是把应用领域的问题，形式化为一个个数学问题。
      - 在找到数学问题的“解法”之后，用写程序的方式翻译成实际应用的“算法”。
      - 能够应用“数学”的方式来解决问题，是从一个只能套用现成方案的“码农”向能够将新问题形式化、并找出创新解决方案的“研发工程师”迈出的第一步。
    - 很多问题当知道如何用数学来解决的时候，常常会有醍醐灌顶的感觉。譬如当第一次搞明白，广告中的竞价问题，居然能够变成一个博弈论中“寻找上策均衡”的问题，并且能够通过简简单单的公式表示出来的时候
    - 一旦熟悉机器学习中用到的数学知识，很多想要解决的系统问题，都能通过定义更好的数学优化目标，变成一个能够找到最优解的程序算法，最后通过写个程序，翻译成数学问题来解决
  - 如何学 从工作相关的领域开始，先广度，再深度
    - 从工作相关的领域开始，是让自己一是能有实际用得上学到的知识的机会，二是日常工作中容易耳濡目染，相当于常常在复习。
    - 先有广度，是让自己在心中有一个问题到解决方法的“地图”，遇到具体的问题能够对得上，容易获得正反馈
    - 再有深度，具体去对一个特定的主题学习应用。
  - 当开始深入学一个特定问题的时候，最好的方式是，追一门在线课程，譬如 Coursera、TEDx，或者在极客时间上找一门课程来学习。
    - 在线课程有明确的节奏，通常还会提供作业和测验。
    - 通过作业和测验，让自己对自己的学习有一个联系和反馈的过程。即使实践中没有足够的应用，过一段时间有些知识没有那么熟悉了，但是也容易建立自己很快可以“捡”回来的信心，降低“复习”的启动成本。
    - 跟随在线课程的节奏，可以有效避免“三天打渔两天晒网”的恶习，让学习有始有终。
  - 针对学习的内容写一点程序 把正在学习的问题的解法，写一个算法实现出来。这是一个非常有效的练习方式。譬如学习线性代数，理解仿射，反复读书的效率对我来说，就不如找来 Coding The Matrix，通过写程序，让学习、理解变得更深入。
- 王天一 “数学是工具而非问题，是手段而非目的”
  - 在数学的学习中，首要的问题是明确需求。作为非数学专业出身的“外行”，使用数学的目的不是顶天，而是立地；不是上下求索艰深的理论问题，而是将生活中的具体问题抽象化，进而加以解决。
  - 学习数学的基础在于经验而非哲学，比较实际的思路是秉持功利主义的原则，用多少学多少。掌握基本的线性代数与矩阵论、概率论与数理统计知识足以应付日常的使用，盲目地好高骛远通常有害无益。理论化和公理化这些比较深邃的尝试固然让人着迷，但它们可能并没有肉眼可见的实用性，对于绝大部分计算机从业者恐怕过于阳春白雪。
  - 在学习时还要理解数学的本质。数学是工具而非问题，是手段而非目的。探索世界奥秘的学科是“格物穷理”的物理学，相形之下，数学更像是个任人打扮的小姑娘，它存在的意义就是通过合理的设计简化物理学的研究。正因如此，在数学中存在着各种各样在现实中不可能出现的理想化模型（比如无穷小和极限的诞生），也存在着对同一个物理过程不同的建模方式（比如矩阵力学和波动力学）。充分理解数学的人造特质，可以在学习中少走很多无谓的弯路。
  - 理解数学的工具属性就会自然而然地引出了数学学习中的另一个关键点，那就是工具设计的出发点，也就是所谓的数学思想与数学逻辑。任何一个工具都不是平白无故地设计出来的，它必然要解决某个特定的问题，比如线性代数与矩阵论是对具体对象的抽象表示与运算，比如概率论和数理统计是对不确定性及其定型定量表示的建模。因此，在掌握每一种数学工具的微观技巧之前，理解它们的宏观目标是更加重要的。只有掌握了工具诞生的背景与目的，才有可能有效地使用它们。
  - 数学绝不仅仅是算术，把主要精力放在计算上未免因小失大。在经典科幻《银河系漫游指南》中，超级计算机告诉人们，世界的终极答案是“42”——这更像是对数字主义者善意嘲讽的一个梗。但对算术的过度强调并不鲜见，在相当数量的现行数学教材中，讲解线性代数时开篇便给出行列式的计算方法，这种编排着实让人费解。
  - 学习时值得突出强调的一点是举一反三的能力。同一种工具及其背后的思想可以出现在不同的场景下，解决不同的问题，但是一旦深入到本质层面，就会发现它们实际上是相通的。如何透过现象看本质，将不同场景融会贯通，才是值得锻炼的高级能力。
  - 同一个工具存在不同应用的例子不胜枚举：
    - 特征向量计算的是系统的不动点，在数据降维中有举足轻重的作用，但如果熟悉电子通信的话你就会知道，对线性时不变系统的分析（也就是各种变换）都是基于特征向量展开的
    - 在给定隐马尔可夫模型的观测序列时，可以利用维特比算法求解后验概率最大的状态序列，将这一方法应用在信道编码中，就是最经典的卷积码译码算法
    - 在分类问题中，以类间方差最大化为标准可以推导出线性判别分析和决策树等模型，应用在图像处理中，类间方差最大化原理给出的就是图像分割中的 Otsu 方法。
    - 把握数学的工具属性，学习具体方法时先溯因再求果，勤于思考解决相同问题的不同方法，与解决不同问题的相同方法之间的联系与区别
- 结构内容
  - 据结结构
    - 数组和链表就体现了迭代和递归的思想
  - 编程语句
    - 判断语句就是使用了逻辑（布尔）代数
    - 架构在这些数据结构和编程语句之上的算法，除了迭代和递归，也体现了排列、组合和动态规划等思想。
  - 基础算法
  - 机器学习算法
    - 需要理解概率统计和线性代数的核心思想，包括什么是概率、贝叶斯定理、数据的统计分布、向量、矩阵、线性方程等等。
- [code](https://github.com/shuang790228/GeekTime-MathLecture-JavaCode)

![[math_knowlegde_struct.png]]

## 基础思想

### 二进制

- 罗马数字
  - Ⅰ、Ⅱ、Ⅲ 代替手指数量，一只手 “Ⅴ”形，两只手 “ⅤⅤ”
- 阿拉伯数字
  - 由从 0 到 9 这样 10 个计数符号组成，并采取进位制法，高位在左，低位在右，从左往右书写
  - 由于阿拉伯数字本身笔画简单，演算便利，因此逐渐在各国流行起来，成为世界通用数字
- 十进制 decimal
  - 10 称为十进制计数法的基数
- 二进制 binary
  - 数位是 2^n 形式
- 计算机使用二进制和现代计算机系统的硬件实现有关。组成计算机系统的逻辑电路通常只有两个状态，即开关的接通与断开
  - 断开状态用“0”来表示，接通的状态用“1”来表示。
  - 由于每位数据只有断开与接通两种状态，所以即便系统受到一定程度的干扰时，它仍然能够可靠地分辨出数字是“0”还是“1”。
  - 在具体系统实现中，二进制数据表达具有抗干扰能力强、可靠性高的优点。
  - 适合逻辑运算
  - 逻辑运算中的加法（“或”运算）、乘法（“与”运算）以及否定（“非”运算）都可以通过“0”和“1”的加法、乘法和减法来实现。
- 负整数转换为二进制 将负整数对应正整数先转换成二进制，然后对其“取补”，再对取补后的结果加1

#### signed

- 符号位 有符号二进制数中的最高位，需要它来表示负数
  - 在实际的硬件系统中，计算机 CPU 的运算器只实现了加法器，而没有实现减法器。通过加上一个负数来达到这个目的
  - 有符号数（signed）最高位是符号位, 0 时，表示为正数；1 时，表示为负数
  - 无符号数（unsigned）最高位就不是符号位，而是二进制数字的一部分
  - Java 所有和数字相关的数据类型都是有符号位的
- 溢出 二进制数位数超过系统所指定位数。目前主流系统都支持至少 32 位整型数字
  - n 位数字 -2^(n-1) ~2^(n-1)-1
  - 符号位是 1，后面 n-1 位全是 0 表示 -2^(n-1)
  - 上溢出（overflow） 超出上限
  - 下溢出（underflow）超出下限
- 溢出后，从下限开始 最大数值加 1，变成最小数值，周而复始
  - 相当于取模
  - 取模的除数 数据类型上限减去下限的值，再加 1 `(2^(n-1)-1)-(-2^(n-1))+1=2x2^(n-1)-1+1=2^n-1+1` 为什么不直接写成 2^n 呢？因为 2^n 已经是 n+1 位了，超出 n 位所能表示的范围

![[num_flow.png|溢出]]

#### encode

- 原码 二进制的原始表示。对于有符号二进制来，原码最高位是符号位，其余位表示该数字绝对值的二进制
  - 零二异性 10000 00000 都表示 0
- 减法计算不能通过负数原码实现 `3+(-2)`
- i-j，其中 j 为正数。如果 i-j 加上取模的除数，会形成溢出，并正好能够获得 i-j 运算结果
- `i-j=(i-j)+(2^n-1+1)=i+(2^n-1-j)+1=i 原码 +(-j 反码)+1=i 原码 +(-j 补码)=i 补码 +(-j 补码)`
  - 2^n-1 不考虑符号位情况 n-1 位的 1
  - 2^n-1-j  对正数 j 二进制原码，除符号位之外按位取反（0 变 1，1 变 0）
  - 负数 -j 和正数 j 原码，除符号位之外都相同,2^n-1-j 也相当于对负数 -j 的二进制原码，除符号位之外按位取反
  - 2^n-1-j 编码称为负数 -j 反码， 反码是负数的一种表示，正数保持不变
- 把 -j 反码加上 1 定义 -j  补码
- 正数原码、反码和补码三者都一样
- 计算机通过补码正确地运算二进制减法

![[bin_substract.png|]]

#### bit operator 位操作|位运算

- 直接对内存中二进制位进行操作
- 向左移位
  - 溢出 需要将溢出的位数去除
  - 数学意义就是将数字翻倍
- 向右移位 去除末尾位
  - 数学意义 数字除以 2 并求整数商的操作
  - 逻辑右移 右移 1 位，左边补 0 即可
    - 在 Java 和 Python 语言中使用 >>> 表示
  - 算术右移 保持符号位不变，除符号位之外的右移一位并补符号位 1。补的 1 仍然在符号位之后。
  - 在 C 或 C++ 语言中，逻辑右移和算数右移共享同一个运算符 >>，编译器是如何决定使用逻辑右移还是算数右移呢？
    - 取决于运算数类型 unsigned 采用逻辑右移; signed 采用算数右移
    - unsigned 类型算数右移，或者 signed 类型逻辑右移，首先需要进行类型转换
- 或
- 与
  - 验证奇偶数
    - 偶数二进制最后一位总是 0，而奇数的二进制最后一位总是 1
    - 和数字 1 二进制进行按位“与”操作，取得数字二进制最后一位，再进行判断
- 异或
  - 排异性 参与操作的位相同，结果为 0（假），否则为 1（真）
  - 所有数值和自身进行按位“异或”操作之后都为 0。而且要通过“异或”操作得到 0，也必须通过两个相同的数值进行按位“异或”。
  - 两个数值按位“异或”结果为 0 <=> 两个数值相等 可以作为判断两个变量是否相等的条件。
  - 交换两个数字
- 集合操作
  - 集合转换成 BitSet
  - 集合{1, 3, 8}和{4, 8},转为两个 8 位二进制数，从右往左以 1 到 8 依次来编号,如果某个数字在集合中，相应的位置 1，否则置 0
  - 10000101  10001000
  - 与 代表两个集合的交
  - 或 代表两个集合的并
  - elasticsearch 的filter查询，用 bitset 就是位运算

```java
x = (x ^ y);
y = x ^ y;
x = x ^ y;
```

### 余数：原来取余操作本身就是个哈希函数

- 余数总是在一个固定的范围内。
- 取余可以通过某一种关系，让没有边界的整数处于一个确定的边界内 无线=>有限
- 同余定理 两个整数 a 和 b，如果它们除以正整数 m 得到余数相等，可以说 a 和 b 对于模 m 同余
  - 奇数和偶数是同余定理的一个应用
- **用来分类** 把无穷多个输入分成有限多个类
- 哈希（Hash）|散列 将任意长度输入，通过哈希算法，压缩为某一固定长度的输出
  - 哈希函数 f(x) = (x + MAX) mod size
  - 较大随机数 MAX 被分配到同一个空间中的记录就更加“随机”，更适合需要将数据重新洗牌的应用场景，比如加密算法、MapReduce 中的数据分发、记录的高速查询和定位等等。
- 加密算法
- 循环冗余校验
- 真正学懂数学的人却没几个。希望可以从余数这个小概念开始，认识到数学思想其实非常实用，用好这些知识，对编程，甚至生活都有意想不到的作用。

### 迭代 Iterative

- 不断地用旧变量值，递推计算新变量值
- 通过循环语言来实现
- 求数值的精确或者近似解
  - 二分法（Bisection method）
    - 计算某个给定正整数 n（n>1）的平方根
    - 平方根一定小于 n 本身，并且大于 1
    - 二分查找 假设值在目标值左右不断波动，最后到达误差范围内
    - deltaThreshold 误差阈值 控制解的精度
    - 用 maxTry 控制循环的次数。之所以没用 while(true) 循环，是为避免死循环
  - 牛顿迭代法（Newton’s method）
    - 牛顿在 17 世纪提出的一种方法，用于求方程的近似解。
    - 以微分为基础，每次迭代的时候，会去找到比上一个值更接近方程的根，最终找到近似解。
- 在一定范围内查找目标值。典型方法包括二分查找
  - 在自然语言处理中，常要处理同义词或者近义词扩展。手头上会有一个同义词 / 近义词的词典。对于一个待查找单词，需要在字典中找出这个单词，以及它所对应的同义词和近义词，然后进行扩展。
  - 比如说，字典里有一个关于“西红柿”的词条，其同义词包括了“番茄”和“tomato”。
    - 处理文章时，看到“西红柿”这个词，就去字典里查一把，拿出“番茄”“tomato”等等，并添加到文章中作为同义词 / 近义词扩展
    - 用户在搜索“西红柿” 的时候，就能确保出现“番茄”或者“tomato”文章会被返回给用户
  - 用二分查找法进行字典查询
    - 将整个字典先进行排序（假设从小到大）。二分法中很关键的前提条件是，所查找的区间是有序的。这样才能在每次折半的时候，确定被查找的对象属于左半边还是右半边。
    - 使用二分法逐步定位到被查找的单词。每次迭代的时候，都找到被搜索区间的中间点，看看这个点上的单词，是否和待查单词一致。如果一致就返回；如果不一致，要看被查单词比中间点上的单词是小还是大。如果小，那说明被查的单词如果存在字典中，那一定在左半边；否则就在右半边。
    - 根据第二步的判断，选择左半边或者后半边，继续迭代式地查找，直到范围缩小到单个的词。如果到最终仍然无法找到，则返回不存在。
- 机器学习算法中的迭代。相关算法或者模型有很多，比如 K- 均值算法（K-means clustering）、PageRank 的马尔科夫链（Markov chain）、梯度下降法（Gradient descent）等等。迭代法之所以在机器学习中有广泛的应用，是因为很多时候机器学习的过程，就是根据已知的数据和一定的假设，求一个局部最优解。而迭代法可以帮助学习算法逐步搜索，直至发现这种解。

### 数学归纳法 Mathematical Induction

- 平时谈的“归纳” 一种从经验事实中找出普遍特征的认知方法
- 数学归纳法一般步骤：
  - 证明基本情况（通常是 n=1 的时候）是否成立
  - 假设 n=k−1 成立，再证明 n=k 也是成立的（k 为任意大于 1 的自然数）
- 最大特点在于“归纳”二字。已经总结出了规律。只要能够证明规律是正确的，就没有必要进行逐步推算，可以节省很多时间和资源。
- 数学归纳法并不是通过经验或样本观察总结出事物的普遍特征和规律
- 数学归纳法在理论上证明了命题是否成立
- 需要能做出合理的命题假设，然后才能进行证明。虽然很多时候要做这点比较难，确实也没什么捷径。就是要多做题，多去看别人是怎么解题的，自己去积累经验。

#### 递归调用和数学归纳的逻辑是一样的？

- 在数学归纳法的第二种情况下，假设 n=k−1 的时候命题成立。在代码实现中，可以将伪代码的第二步转为函数的递归（嵌套）调用，直到被调用的函数回退到 n=1 情况。然后，被调用的函数逐步返回 k−1 时命题是否成立。
- 递归调用的代码和数学归纳法的逻辑是一致的
- 和数学归纳证明稍有不同的是，递归编程代码需要返回若干的变量，来传递 k−1 的状态到 k
- 递归调用流程
  - 函数从 k=63 开始调用，然后调用 k−1，也就是 62，一直到 k=1 的时候，嵌套调用结束，k=1 的函数体开始返回值给 k=2 的函数体，一直到 k=63 的函数体。
  - 逆向递推 从 k=63,62,…,2,1 的嵌套调用过程，其实就是体现了数学归纳法的核心思想
  - 正向递推 从 k=1,2,…,62,63 的值返回过程，和基于循环的迭代是一致的

![[cursive.png]]

### 递归

> 舍罕王 直接给固定数额的货币奖赏
> 宰相 有个小小的要求。那就是能否列出所有可能的奖赏方式，让我自己来选呢？
> 假设有四种面额的钱币，1 元、2 元、5 元和 10 元，而您一共给我 10 元，
> 那可以奖赏我 1 张 10 元，或者 10 张 1 元，或者 5 张 1 元外加 1 张 5 元等等
> 如果考虑每次奖赏金额和先后顺序，那么最终一共有多少种不同的奖赏方式呢？

- 泛化数学归纳，将复杂问题简单化
  - 递归函数值返回过程和基于循环的迭代法一致，直接用迭代法不就好了，为什么还要用递归的数学思想和编程方法呢？
    - 在某些场景下，递归解法比基于循环的迭代法更容易实现
  - 在递归中，每次嵌套调用都会让函数体生成自己的局部变量，可以用来保存不同状态下的数值，省去了大量中间变量的操作，极大地方便了设计和编程
  - 归纳是思想，递归是实现。如何转化归纳
    - 将复杂的问题，每次都解决一点点，并将剩下的任务转化成为更简单的问题等待下次求解，如此反复，直到最简单的形式
  - 如何将数学归纳法的思想泛化成更一般的情况
    - 假设 n=k-1 时，问题已经解决（或者已经找到解）。只要求解 n=k 时候，问题如何解决（或者解是多少）
    - 初始状态， n=1 时，如何解决（或者解是多少）
  - 递归和循环其实都是迭代法的实现，而且在某些场合下，它们的实现是可以相互转化的
  - 递归采用逆向递推，化繁为简，把复杂问题逐步简化。再加上分治原理，就可以更有效地把问题细分，进行并行化的处理。计算机编程中的函数嵌套调用，正好对应了数学中递归的逆向递推
  - 递归编程在没有开始返回结果之前，保存了大量中间结果，所以比较消耗系统资源。这也是一般的编程语言都会限制递归的深度
  - 对于某些应用场景，递归确很难被循环取代
    - 一个当前所采取的步骤可能是进行一次运算（例如每个棋格里的麦粒数是前一格的两倍），或者做一个选择（例如选择不同面额的纸币），或者是不同类型操作的结合（例如今天讲的赏金的案例）等等。
    - 另一个更简单的问题。经过上述步骤之后，问题就会变得更加简单一点。这里“简单一点”，指运算的结果离目标值更近（例如赏金的总额），或者是完成了更多的选择（例如纸币的选择）。而“更简单的问题”，又可以通过嵌套调用，进一步简化和求解，直至达到结束条件。
    - 只需要保证递归编程能够体现这种将复杂问题逐步简化的思想，那么它就能帮助解决很多类似的问题。
    - 第二，递归会使用计算机的函数嵌套调用。而函数的调用本身，就可以保存很多中间状态和变量值，因此极大的方便了编程的处理。
- 分而治之，从归并排序到 MapReduce
  - 分而治之（Divide and Conquer）分治
    - 思想 将一个复杂的问题，分解成两个甚至多个规模相同或类似的子问题，然后对这些子问题再进一步细分，直到最后的子问题变得很简单，很容易就能被求解出来，这样这个复杂的问题就求解出来了。
  - 归并排序 merge sort
    - 把长度为 n 的数列，每次简化为两个长度为 n/2 的数列。这更有利于计算机的并行处理，只需要 log2n 次归并
    - 用分治的思想把数列不断地简化，直到每个数列仅剩下一个单独的数，然后再使用归并逐步合并有序的数列，从而达到将整个数列进行排序的目的。而这个归并排序，正好可以使用递归的方式来实现
    - 在递归的每次嵌套调用中，代码都将一组数分解成更小的两组，然后将这两个小组的排序交给下一次的嵌套调用。而本次调用只需要关心，如何将排好序的两个小组进行合并。
  - 分布式系统中的分治思想
    - 当需要排序的数组很大（比如达到 1024GB 的时候），没法把这些数据都塞入一台普通机器的内存里。可以把这个超级大的数据集，分解为多个更小的数据集（比如 16GB 或者更小），然后分配到多台机器，让它们并行地处理。
    - 等所有机器处理完后，中央服务器再进行结果的合并。由于多个小任务间不会相互干扰，可以同时处理，这样会大大增加处理的速度，减少等待时间。
    - 在单台机器上实现归并排序的时候，只需要在递归函数内，实现数据分组以及合并就行了。而多个机器之间分配数据的时候，递归函数内除了分组及合并，还要负责把数据分发到某台机器上。
    - 注意 父结点都没有被分配排序的工作，只是在子结点的排序完成后进行有序数组的合并，因此集群的性能没有得到充分利用。那么，另一种可能的数据切分方式是，每台机器拿出一半的数据给另一台机器处理，而自己来完成剩下一半的数据。
    - 分治的时候，只进行一次问题切分，那么层级型分布式架构就可以转化为类似 MapReduce 的架构
    - 步骤
      - 数据分割和映射
        - 分割是指将数据源进行切分，并将分片发送到 Mapper 上。
        - 映射是指 Mapper 根据应用的需求，将内容按照键 - 值的匹配，存储到哈希结构中。
        - 这两个步骤将大数据集合切分为更小的数据集，降低每台机器节点的负载，因此和分治中的问题分解类似。
        - MapReduce 采用哈希映射来分配数据，而普通的分治或递归不一定需要。
      - 归约
        - 指接受到的一组键值配对，如果是键内容相同的配对，就将它们的值归并。这和本机的递归调用后返回结果的过程类似。
        - 由于哈希映射的关系，MapReduce 还需要洗牌步骤，也就是将键 - 值的配对不断地发给对应的 Reducer 进行归约。普通的分治或递归不一定需要洗牌的步骤。
      - 合并
        - 为提升洗牌阶段效率，选择减少发送到归约阶段的键 - 值配对。
        - 具体做法 在数据映射和洗牌之间，加入合并过程，在每个 Mapper 节点上先进行一次本地的归约。只将合并结果发送到洗牌和归约阶段。这和本机的递归调用后返回结果的过程类似。
- 时间复杂度是O(NlogN)
  - 3路归并排序  T(n)= 3T(n/3)+ O(n)

![[merge_sort.png]]
![[map_reduce_arch.png]]

#### 迭代法和递归  归纳

- 迭代法和递归都是通过不断反复的步骤，计算数值或进行操作的方法。
  - 迭代一般适合正向思维，而递归一般适合逆向思维。
  - 递归回溯的时候，也体现了正向递推的思维。本身都是抽象的流程，可以有不同的编程实现。
- 对于某些重复性的计算，数学归纳法可以从理论上证明某个结论是否成立。如果成立，它可以大大节约迭代法中数值计算部分的时间。不过，在使用数学归纳法之前，我们需要通过一些数学知识，假设命题，并证明该命题成立。
- 对于那些无法使用数学归纳法来证明的迭代问题，我们可以通过编程实现。这里需要注意的是，广义上来说，递归也是迭代法的一种。不过，在计算机编程中，我们所提到的迭代是一种具体的编程实现，是指使用循环来实现的正向递推，而递归是指使用函数的嵌套调用来实现的逆向递推。当然，两种实现通常是可以相互转换的。
- 循环的实现很容易理解，对硬件资源的开销比较小。不过，循环更适合“单线剧情”，例如计算 2^n，n!，1+2+3+…+n 等等。而对于存在很多“分支剧情”的复杂案例而言，使用递归调用更加合适。
- 利用函数的嵌套调用，递归编程可以存储很多中间变量。我们可以很轻松地跟踪不同的分支，而所有这些对程序员基本是透明的。如果这时使用循环，我们不得不自己创建并保存很多中间变量。当然，正是由于这个特性，递归比较消耗硬件资源。
- 递归编程本身就体现了分治的思想，这个思想还可以延伸到集群的分布式架构中。最近几年比较主流的 MapReduce 框架也体现了这种思想。
- 综合上面说几点，大致遵循这样原则
  - 如果一个问题可以被迭代法解决，而且是有关数值计算的，那就看看是否可以假设命题，并优先考虑使用数学归纳法来证明
  - 如果需要借助计算机，那么优先考虑是否可以使用循环来实现。如果问题本身过于复杂，再考虑函数的嵌套调用，是否可以通过递归将问题逐级简化
  - 如果数据量过大，可以考虑采用分治思想的分布式系统来处理

### 排列 Permutation

> t1，t2 和 t3 表示田忌上、中、下等马跑完全程所需时间，用 q1，q2 和 q3 分别表示齐王上、中、下等马跑全程所需时间，`q1<t1<q2<t2<q3<t3`

- 从 n 个不同的元素中取出 m（1≤m≤n）个不同元素，按照一定顺序排成一列
- 全排列 All Permutation  当 m=n 这种特殊情况出现的时候
- 如果选择出的这 m 个元素可以有重复的，这样的排列就是为重复排列（Permutation with Repetition），否则就是不重复排列（Permutation without Repetition）
- 其实是一个树状结构。从树的根结点到叶子结点，每种路径都是一种排列。有多少个叶子结点就有多少种全排列
- 将这些可能的排列，仔细地和齐王的上等、中等和下等马进行对比，只有{下等，上等，中等}这一种可能战胜齐王，也就是 t3>q1，t1<q2，t2<q3。
- 对于 n 个元素全排列，所有可能的排列数量就是 nx(n-1)x(n-2)x…x2x1= n!
- 对于 n 个元素里取出 m(0<m≤n) 个元素不重复排列数量 nx(n-1)x(n-2)x…x(n - m + 1)= n!/(n-m)!
- 把田忌赛马的案例，转成计算机所能理解的内容
  - 在不同选马阶段,都要保存已经有几匹马出战、它们的排列顺序、以及还剩几匹马没有选择。变量 result 来存储到当前函数操作之前，已出战马匹及其排列顺序。变量 horses 存储到当前函数操作之前，还剩几匹马还没出战。变量 new_result 和 rest_horses 分别从 result 和 horses 克隆而来，保证不会影响上一次的结果。
  - 孙膑的方法之所以奏效，是因为他看到每一等马中，田忌的马只比齐王的差一点点。如果相差太多，可能就会有不同的胜负结局。所以，在设置马匹跑完全程的时间上，特意设置为 q1<t1<q2<t2<q3<t3，只有这样才能保证计算机得出和孙膑相同的结论。
- 暴力破解密码
  - 黑客们并不需要真的拿到密码，而是通过“猜”，也就是列举各种可能密码，然后逐个地去尝试密码正确性。如果某个尝试的密码正好和原先管理员设置的一样，那么系统就被破解
  - 从 n（这里 n 为 52）个元素取出 m（0<m≤n）个元素的可重复全排列，总数量为 n^m
  - solution
    - 限定一定时间内尝试密码的次数
    - 使用多种类型字符创建密码
    - 增加密码长度
- 最多用途 穷举法 列出所有可能情况，一个一个验证，然后看每种情况是否符合条件的解。

### 组合 Combination

- 不考虑每个元素出现的顺序的 从 n 个不同元素中取出 m（1≤m≤n）个不同的元素
- 对于所有 m 取值的组合之全集合，我们可以叫作全组合（All Combination）。例如对于集合{1, 2, 3}而言，全组合就是{空集, {1}, {2}, {3}, {1, 2}, {1,3} {2, 3}, {1, 2, 3}}。
- n 个元素里取出 m 个的组合可能性数量  n 个里取 m 个的排列数量，除以 m 个全排列的数量，也就是 (n! / (n-m)!) / m!
- 全组合而言，可能性为 2^n 种
- 多元文法
  - 把临近的几个单词合并起来，组合一个新的词组
  - 只是为了方便计算机的处理，而不考虑组合后的词组是不是有正确的语法和语义。
  - 普通的多元文法本身存在一个问题，那就是定死了每个元组内单词出现的顺序,并不要求查询词组中单词所出现的顺序和原文一致
  - 把每个二元或三元组进行全排列，得到所有的可能。但是这样的话，二元组的数量就会增加 1 倍，三元组的数量就会增加 5 倍，一篇文章的数据保存量就会增加 3 倍左右。我也试过对用户查询做全排列，把原有的二元组查询变为 2 个不同的二元组查询，把原有的三元组查询变为 6 个不同的三元组查询，但是事实是，这样会增加实时查询的耗时。
  - 组合 多个单词出现时，并不关心它们的顺序（也就是不关心排列），而只关心它们的组合。因为无需关心顺序，就意味着可以对多元组内的单词进行某种形式的标准化。即使原来的单词出现顺序有所不同，经过这个标准化过程之后，都会变成唯一的顺序。

### 动态规划 Dynamic Programming

- 只要找到满足条件的最优解就行了,需要在各种可能的局部解中，找出那些可能达到最优的局部解，而放弃其他的局部解。这个寻找最优解的过程
- 通过子问题的最优解，推导出最终问题的最优解，特别注重子问题之间的转移关系。
- 把子问题之间的转移称为状态转移，并把用于刻画这些状态转移的表达式称为状态转移方程
- 编辑距离 Edit Distance 由一个字符串转成另一个字符串所需的最少编辑操作次数
  - 俄罗斯科学家莱文斯坦提出来的，所以也称作莱文斯坦距离（Levenshtein distance）
  - 查询推荐 搜索下拉提示和关键词纠错，核心思想 对于用户输入，查找相似关键词并进行返回
  - 测量拉丁文的文本相似度，最常用指标 编辑距离
  - 操作 把一个字符替换成另一个字符；插入一个字符；删除一个字符
  - 编辑距离只需要求最小操作次数，并不要求列出所有的可能。而且排列过程非常容易出错，还会浪费大量计算资源
  - 细分
    - 增加
      - 假设字符串 A 和 B 都是空字符串，编辑距离 0
      - 如果 A 增加一个字符 a1，B 保持不动，编辑距离增加 1
      - 如果 B 增加一个字符 b1，A 保持不动，编辑距离增加 1
    - 插入字符
      - A 字符串是 a1，B 空串增加一个字符变为 b1
      - B 字符串为 b1 ，A 空串增加一个字符变为 a1
      - 编辑距离都要增加 1
    - 替换字符
      - 当 A 和 B 都是空串，同时增加一个字符
      - 要加入字符 a1 和 b1 不相等，表示 A 和 B 之间转化的时候需要替换字符，那么编辑距离就是加 1
      - 如果 a1 和 b1 相等，无需替换，那么编辑距离不变
    - 取上述三种情况中编辑距离的最小值作为当前的编辑距离。注意只需要保留这个最小的值，而舍弃其他更大的值。这是为什么呢？因为编辑距离随着字符串的增长，是单调递增的。所以，要求最终的最小值，必须要保证对于每个子串，都取得了最小值。有了这点，之后就可以使用迭代的方式，一步步推导下去，直到两个字符串结束比较。
    - 没有删除，这是因为删除就是插入的逆操作。如果从完整的字符串 A 或者 B 开始，而不是从空串开始，这就是删除操作了。
    - 用 mouuse 和 mouse 例子 把 mouuse 字符数组作为表格的行，每一行表示其中一个字母，而 mouse 字符数组作为列，每列表示其中一个字母
- 能够使用动态规划解决的问题，通常只关心一个最优解，而这个最优解是单调改变的，例如最大值、最小值等等。因此，动态规划中的每种状态，通常只保留一个当前的最优解，这也是动态规划效率比较高的原因。

![[../_static/status_transmit_process.png]]
![[../_static/status_transmit_table.png]]

## 概率统计

## 线性代数

## 综合应用
